Temperature - It is a value range from 0 to 1. It controls the randomness of the model. If the value is near 0 then it is less random. If the value is nearer to 1 then it is more random

Top P - This is a sampling technique with temperature, called nucleus sampling. If we are looking for exact and factual answers we need to keep this low. If we are looking for more diverse responses then we need increase to a higher value

Max Length - We can manager the number of tokens the model generates by adjusting the max length

Stop sequence -  Specifying stop sequence is another way to control the length and the structure of the model's response

Frequency penalty - It applies a penalty on the next token proportional to how many times that token already appeared in the response and prompt. The higher the frequency penalty, the less likely a word will appear again.

Presence Penalty - The presence penalty also applies a penalty on repeated tokens but, unlike the frequency penalty, the penalty is the same for all repeated tokens. A token that appears twice and a token that appears 10 times are penalized the same. If you want the model to generate diverse or creative text, you might want to use a higher presence penalty. Or, if you need the model to stay focused, try using a lower presence penalty.

System Role:
 The System role is used to provide setup information or context that informs the behavior of the model.
Example: System: The assistant should always maintain a professional tone and avoid discussing personal opinions on politics.

User role: 
This role represents the human user in the conversation. Inputs from the user guide the conversation and prompt responses from the assistant.

Example: User: Can you explain how to integrate Open Ai's API with my existing Python application?

Assistant Role:
 This is the role of the model itself, responding to user inputs based on the context set by the system.

Example: Assistant: Sure, to integrate Open Ai's API with your Python application, youâ€™ll start by installing the Open AI Python package using pip...

A prompt contains any of the following elements:

Instruction - a specific task or instruction you want the model to perform

Context - external information or additional context that can steer the model to better responses

Input Data - the input or question that we are interested to find a response for

Output Indicator - the type or format of the output.

Tips for Designing prompts:
1. Start Simple and be more specific
2. Instruct the models. Eg: Write, Classify, Summary
3. Tell the behavior what you want rather than what to avoid.
4. Avoid Impreciseness

Zero Shot Prompting:
Zero-shot prompting means that the prompt used to interact with the model won't contain examples or demonstrations. We will give a text and ask it do something with it without giving any example on how to perform the task

Few Shot Prompting:
Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.

Chain of thought prompting:
Chain-of-thought (CoT) prompting is a technique that allows large language models to solve a problem as a series of intermediate steps before giving a final answer

Example: 

Prompt: 
The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.

The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.
A: Adding all the odd numbers (17, 19) gives 36. The answer is True.

The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.
A: Adding all the odd numbers (11, 13) gives 24. The answer is True.

The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.
A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.

The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 
A:

Output:
Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.

Zero Shot CoT:
Zero Shot Chain of Thought (Zero-shot-CoT) prompting is a follow up to CoT prompting, which introduces a simple zero shot prompt, by appending the words "Let's think step by step." to the end of a question

Example:

Prompt:I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?

Let's think step by step.

Output:
First, you started with 10 apples.
You gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left.
Then you bought 5 more apples, so now you had 11 apples.
Finally, you ate 1 apple, so you would remain with 10 apples.

Automatic CoT:
When applying chain-of-thought prompting with demonstrations, the process involves hand-crafting effective and diverse examples.

2 main stage in Automatic CoT:
Stage 1): question clustering: partition questions of a given dataset into a few clusters
Stage 2): demonstration sampling: select a representative question from each cluster and generate its reasoning chain using Zero-Shot-CoT with simple heuristics

The simple heuristics could be length of questions (e.g., 60 tokens) and number of steps in rationale (e.g., 5 reasoning steps).


Drawbacks of CoT:
1)Smaller models wrote illogical CoT which had worst accuracy than standard prompting.
Better model size = Better Performance Boost for CoT
2) Naive Greedy Decoding of CoT prompting: It's like writing a story one sentence at a time, and each sentence is based on previous sentence alone, without thinking about bigger picture of the story

Self Consistency:
Self-consistency simply asks a model the same prompt multiple times and takes the majority result as the final answer

General Knowledge prompting:

General Knowledge Prompting can initially yield incorrect responses based on how a question is phrased. A second, more informed prompt can correct and refine the AI's response, demonstrating the importance of context and clarification in prompting.

Example 1:
Prompt: "In chess, can the king move two squares in any direction?"
Output: "Yes, in chess, the king can move two squares in any direction."

This response shows a common misconception about the king's movement in chess, illustrating how the AI can err based on the framing of the question.

Example 2:
Prompt: "Reconsidering the rules of chess, is it true that the king can move two squares in any direction?"
Output: "No, that's incorrect. In chess, the king can only move one square in any direction, except during castling, where it moves two squares towards the rook."

By prompting the AI to reconsider its response in light of the actual rules of chess, it corrects its initial error.

This two-step approach underlines the importance of context and the manner in which questions are posed to ensure accurate responses from General Knowledge Prompting.